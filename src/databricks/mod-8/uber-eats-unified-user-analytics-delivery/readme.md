# UberEats Unified User Analytics - CDC Implementations

## ðŸ“š Overview

This directory contains **two CDC (Change Data Capture) implementation patterns** for the UberEats unified user analytics pipeline, demonstrating different approaches to tracking data changes in Databricks Delta Live Tables.

---

## ðŸ”„ CDC Pattern Comparison

### Pattern 1: Batch CDC (Snapshot-based) âœ… **IMPLEMENTED**
- **Location:** [`batch-cdc/`](batch-cdc/)
- **Method:** `dlt.apply_changes()` with MATERIALIZED VIEWS
- **Use Case:** Snapshot-based change detection from periodic exports
- **Status:** âœ… Production-ready

### Pattern 2: Streaming CDC (Event-based) ðŸš§ **PLANNED**
- **Location:** [`stream-cdc/`](stream-cdc/)
- **Method:** `dlt.read_stream()` with Change Data Feed
- **Use Case:** Real-time CDC events from streaming sources
- **Status:** ðŸš§ Template/documentation only

---

## ðŸ“Š When to Use Each Pattern

| Criteria | Batch CDC | Streaming CDC |
|----------|-----------|---------------|
| **Source Data** | Full snapshots (JSON/CSV exports) | CDC events (Debezium, CDC logs) |
| **Update Frequency** | Hourly/Daily | Real-time (seconds) |
| **Data Volume** | < 10M records/refresh | High-volume transactional |
| **Latency** | Minutes to hours | Seconds |
| **Cost** | ~$50/month | ~$400/month |
| **Complexity** | Lower | Higher |
| **Infrastructure** | File storage | Kafka/Event Hub + CDC connectors |
| **Best For** | User profiles, products, customers | Transactions, IoT, fraud detection |

---

## ðŸŽ¯ Quick Decision Matrix

**Choose Batch CDC if:**
- âœ… Source systems export full snapshots periodically
- âœ… Data changes slowly (user profiles, product catalogs)
- âœ… Hourly/daily freshness is acceptable
- âœ… Cost optimization is priority
- âœ… Simpler implementation is preferred

**Choose Streaming CDC if:**
- âœ… Source systems can produce CDC events
- âœ… Sub-second latency is required
- âœ… High-volume transactional data
- âœ… Event-driven architecture
- âœ… Budget allows 8x higher compute costs

---

## ðŸ“ Directory Structure

```
uber-eats-unified-user-analytics-delivery/
â”‚
â”œâ”€â”€ batch-cdc/                              âœ… Production Implementation
â”‚   â”œâ”€â”€ 01-bronze-mongodb-users.sql        # Snapshot ingestion
â”‚   â”œâ”€â”€ 01-bronze-mssql-users.sql          # Snapshot ingestion
â”‚   â”œâ”€â”€ 02-silver-users-staging.sql        # FULL OUTER JOIN
â”‚   â”œâ”€â”€ 03-silver-users-cdc.py             # apply_changes() - Batch CDC
â”‚   â”œâ”€â”€ 04-gold-*.sql                      # Analytics tables
â”‚   â”œâ”€â”€ databricks.yml                     # Pipeline config
â”‚   â”œâ”€â”€ QUICKSTART.md                      # Quick start guide
â”‚   â””â”€â”€ README.md                          # Batch CDC docs
â”‚
â”œâ”€â”€ stream-cdc/                             ðŸš§ Future Implementation
â”‚   â””â”€â”€ README.md                          # Streaming CDC docs & templates
â”‚
â”œâ”€â”€ readme.md                               ðŸ“„ This file (main overview)
â””â”€â”€ use-case.md                            ðŸ“„ Business use case details
```

---

## ðŸš€ Getting Started

### For Current Implementation (Batch CDC):

```bash
# Navigate to batch CDC implementation
cd batch-cdc/

# Review quick start guide
cat QUICKSTART.md

# Deploy the pipeline
databricks bundle validate
databricks bundle deploy --target production
databricks bundle run uber_eats_user_pipeline
```

See [`batch-cdc/QUICKSTART.md`](batch-cdc/QUICKSTART.md) for detailed deployment instructions.

### For Future Streaming Implementation:

See [`stream-cdc/README.md`](stream-cdc/README.md) for requirements and architecture planning.

---

## ðŸ—ï¸ Architecture Comparison

### Batch CDC Architecture (Current)
```
MongoDB/MSSQL (Full Exports)
    â†“ Hourly/Daily dumps to Blob Storage
Bronze Layer (MATERIALIZED VIEWS)
    â†“ read_files() - Batch ingestion
Silver Staging (MATERIALIZED VIEW)
    â†“ FULL OUTER JOIN
Silver CDC (create_target_table)
    â†“ apply_changes() compares snapshots
    â”œâ”€ SCD Type 1 (current state)
    â””â”€ SCD Type 2 (full history)
Gold Layer (Analytics)
```

### Streaming CDC Architecture (Future)
```
MongoDB/MSSQL (CDC Enabled)
    â†“ Change events to Kafka
Bronze Layer (STREAMING TABLES)
    â†“ read_stream() - Real-time
Silver Staging (STREAMING TABLE)
    â†“ Stream-stream join
Silver CDC (create_streaming_table)
    â†“ apply_changes() from CDC stream
    â”œâ”€ SCD Type 1 (real-time)
    â””â”€ SCD Type 2 (real-time history)
Gold Layer (Real-time analytics)
```

---

## ðŸ’¡ Key Technical Differences

### Batch CDC Implementation
```python
# Bronze: MATERIALIZED VIEW (snapshot)
CREATE OR REFRESH MATERIALIZED VIEW bronze_mongodb_users AS
SELECT * FROM read_files('path/*.json')

# CDC: create_target_table (batch)
dlt.create_target_table(name="silver_users_unified")
dlt.apply_changes(
    target="silver_users_unified",
    source="silver_users_staging",  # MATERIALIZED VIEW
    stored_as_scd_type=1
)
```

### Streaming CDC Implementation
```python
# Bronze: STREAMING TABLE (CDC events)
CREATE OR REFRESH STREAMING TABLE bronze_mongodb_cdc AS
SELECT * FROM cloud_files('path/cdc-events/', 'json')

# CDC: create_streaming_table (streaming)
dlt.create_streaming_table(name="silver_users_unified")
dlt.apply_changes(
    target="silver_users_unified",
    source=dlt.read_stream("silver_users_staging"),  # STREAMING
    stored_as_scd_type=1
)
```

---

## ðŸ“– Business Use Case

**Problem:** UberEats has user data fragmented across:
- **MongoDB:** Operational data (email, delivery address, city)
- **MSSQL:** CRM data (name, birthday, job, company)

**Solution:** Unified user domain with complete profiles and change tracking

**Business Value:**
- ðŸ“ˆ Marketing: 95% profile completeness (vs 50% before)
- ðŸŽ¯ Customer Support: 30-second resolution (vs 5 minutes)
- âš–ï¸ Compliance: 1-hour DSAR response (vs 2 weeks)
- ðŸ“Š Analytics: 85% data quality score (vs 60%)

See [`use-case.md`](use-case.md) for detailed business context.

---

## ðŸŽ“ Learning Outcomes

By studying both implementations, you'll understand:

### Batch CDC (Current):
- âœ… Snapshot-based CDC with `apply_changes()`
- âœ… `create_target_table()` for batch processing
- âœ… MATERIALIZED VIEW pattern
- âœ… Cost optimization strategies
- âœ… SCD Type 1 & Type 2 implementation
- âœ… FULL OUTER JOIN for multi-source unification

### Streaming CDC (Future):
- ðŸ”„ Event-based CDC processing
- ðŸ”„ `create_streaming_table()` for real-time
- ðŸ”„ Change Data Feed consumption
- ðŸ”„ Auto Loader for incremental ingestion
- ðŸ”„ Stream-stream joins
- ðŸ”„ Continuous pipeline patterns

---

## ðŸ’° Cost Analysis

### Monthly Compute Costs (Azure Databricks)

**Batch CDC (Current Implementation):**
- Execution: 2 hours/day Ã— 30 days = 60 hours/month
- Serverless DBUs: ~100 DBUs/month
- Cost: ~$50/month âœ…

**Streaming CDC (If Implemented):**
- Execution: 24 hours/day Ã— 30 days = 720 hours/month
- Serverless DBUs: ~800 DBUs/month
- Cost: ~$400/month âš ï¸

**Trade-off:** Real-time capability = 8x cost increase

For user profile data that changes slowly, **Batch CDC provides 60-80% cost savings** with acceptable latency.

---

## ðŸ”§ Migration Path

If business needs evolve from batch to streaming:

1. **Enable CDC on sources** (MongoDB change streams, MSSQL CDC)
2. **Set up streaming infrastructure** (Kafka, Event Hub, Debezium)
3. **Convert Bronze to STREAMING TABLES**
4. **Update CDC to use `create_streaming_table()`**
5. **Enable continuous mode** in pipeline config
6. **Monitor costs** and performance

---

## ðŸ“š Documentation Links

### Databricks Resources:
- [Batch CDC (apply_changes)](https://docs.databricks.com/aws/en/ldp/what-is-change-data-capture.html)
- [Streaming CDC (CDF)](https://docs.databricks.com/aws/en/ldp/cdc?language=Python)
- [Change Data Feed](https://docs.databricks.com/delta/delta-change-data-feed.html)
- [Auto Loader](https://docs.databricks.com/ingestion/auto-loader/index.html)

### CDC Technologies:
- [Debezium](https://debezium.io/)
- [MongoDB Change Streams](https://www.mongodb.com/docs/manual/changeStreams/)
- [SQL Server CDC](https://learn.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server)

---

## ðŸ¤ Support & Contributions

- **Current Implementation:** See [`batch-cdc/QUICKSTART.md`](batch-cdc/QUICKSTART.md)
- **Questions:** Review README files in each folder
- **Issues:** Check troubleshooting sections in documentation

---

## ðŸŽ¯ Recommendation

**For UberEats user analytics use case:**
- âœ… Use **Batch CDC** (current implementation)
- âœ… User profiles change slowly (perfect for hourly/daily refresh)
- âœ… 60-80% cost savings vs streaming
- âœ… Production-ready, fully tested

**When to consider Streaming CDC:**
- Real-time fraud detection is added
- Order processing needs sub-second updates
- Business can justify 8x higher costs
- CDC infrastructure is already in place

---

**Choose the right pattern for your data velocity and business needs! ðŸš€**
