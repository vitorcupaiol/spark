# USE CASE 1: Real-Time Delivery Monitoring with Streaming

## ğŸ¯ Business Context

**UberEats** processes **thousands of deliveries simultaneously** across multiple cities. Each delivery generates real-time events from multiple systems:

1. **Orders System** (Kafka)
   - New orders placed by customers
   - Order details: restaurant, driver, amount, timestamp

2. **Status Tracking System** (Kafka)
   - Delivery status updates (placed, preparing, picked up, delivered)
   - Real-time status changes throughout delivery lifecycle

3. **GPS System** (Kafka - future extension)
   - Driver location updates
   - Route tracking

4. **Payment System** (Kafka - future extension)
   - Payment confirmations
   - Transaction details

**The Problem**:
- **Operations** needs to monitor all deliveries in **real-time**
- **Delayed orders** must be detected in **< 3 seconds**
- **External systems** (alerting, monitoring) need critical events
- **Analytics** needs real-time KPIs (orders/min, avg delivery time)
- **Restaurant/Driver performance** must be tracked continuously

**The Challenge**:
- Process **10,000+ events/second** with low latency
- **Join** multiple streaming sources (orders + status)
- **Filter** critical events (delayed orders)
- **Publish** alerts to external Kafka topic (Sink)
- **Aggregate** metrics in real-time (windowed aggregations)
- Handle **late-arriving data** (watermarking)

---

## ğŸ—ï¸ Solution Architecture

### **Lakeflow Declarative Pipelines + Medallion Architecture + Streaming + Sinks**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              REAL-TIME DELIVERY MONITORING SYSTEM                     â”‚
â”‚                                                                       â”‚
â”‚  Goal: Monitor deliveries in real-time and alert on critical events  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“¥ DATA SOURCES (Kafka Streams)
    â”œâ”€ kafka/orders/ (New orders)
    â””â”€ kafka/status/ (Status updates)
    â†“
ğŸŸ¤ BRONZE LAYER (Raw Streaming Ingestion)
    â”œâ”€ bronze_orders (Streaming Table - Python Auto Loader)
    â””â”€ bronze_status (Streaming Table - SQL read_files)
    â†“
ğŸ¥ˆ SILVER LAYER (Stream Processing & Joins)
    â”œâ”€ silver_order_status (Stream-to-stream JOIN with watermarking)
    â””â”€ silver_delayed_orders (Filtered critical events)
    â†“
    â”œâ”€â”€â†’ ğŸ“¤ SINK LAYER (External Integration)
    â”‚    â”œâ”€ delivery_alerts_sink (Kafka endpoint)
    â”‚    â””â”€ sink_kafka_alerts (Formatted messages)
    â”‚
    â””â”€â”€â†’ ğŸ¥‡ GOLD LAYER (Real-Time Analytics)
         â”œâ”€ gold_restaurant_performance (Per-restaurant metrics)
         â”œâ”€ gold_driver_performance (Per-driver metrics)
         â”œâ”€ gold_delivery_time_distribution (Speed bucketing)
         â””â”€ gold_system_health (Platform-wide KPIs)
    â†“
ğŸ“Š CONSUMERS (Dashboards, Alerting Systems, ML Models)
```

---

## ğŸ“‹ Detailed Use Case Plan

### **PHASE 1: Bronze Layer - Raw Streaming Ingestion**

**Duration**: 10 minutes

**What Happens**:
- Ingest raw streaming data from **Kafka topics** into Bronze layer
- Use **Streaming Tables** (continuous processing)
- Demonstrate **two approaches**: Python (Auto Loader) + SQL (read_files)
- Enable **Change Data Feed** for downstream lineage

**Why Streaming Tables?**
- Delivery events happen **in real-time** (not batch)
- Need **continuous processing** (not scheduled)
- **Sub-second latency** required for operations

**Tables Created**:

1. **bronze_orders** (Python with Auto Loader)
   - **Source**: Azure Blob Storage (`kafka/orders/*.json`)
   - **Method**: `spark.readStream.format("cloudFiles")`
   - **Features**:
     - Schema hints for type safety
     - Metadata enrichment (`_metadata.file_path`, `_metadata.file_modification_time`)
     - Change Data Feed enabled (`delta.enableChangeDataFeed = true`)
   - **Fields**: user_key, restaurant_key, driver_key, payment_id, order_id, total_amount, order_date, dt_current_timestamp
   - **Type**: STREAMING TABLE
   - **Language**: Python (PySpark)

2. **bronze_status** (SQL with read_files)
   - **Source**: Azure Blob Storage (`kafka/status/*.json`)
   - **Method**: `read_files('path', format => 'json')`
   - **Features**:
     - Nested field extraction (`status.status_name`)
     - Direct SQL syntax (simpler for SQL users)
     - Change Data Feed enabled
   - **Fields**: order_identifier, status_id, status_name, dt_current_timestamp
   - **Type**: STREAMING TABLE
   - **Language**: SQL

**Key Concepts Demonstrated**:
- âœ… Streaming Tables (continuous processing)
- âœ… Auto Loader (cloudFiles) vs read_files
- âœ… Python vs SQL syntax (same result, different approach)
- âœ… Schema hints for type safety
- âœ… Metadata enrichment
- âœ… Change Data Feed for lineage

---

### **PHASE 2: Silver Layer - Stream Processing & Joins**

**Duration**: 15 minutes

**What Happens**:
- **Join** two streaming sources (orders + status) in real-time
- Apply **watermarking** to handle late-arriving data
- Use **time-bounded join** to prevent unbounded state
- Add **Data Quality expectations** (3 rules)
- **Filter** critical events (delayed orders)

**The Challenge**:
Stream-to-stream joins are **complex**:
- Both sides are **unbounded** (infinite data)
- Events can arrive **out of order**
- Without watermarking, **state grows forever** (OOM)
- Need to define **how long to wait** for matching events

**Tables Created**:

1. **silver_order_status** (Stream-to-stream JOIN)
   - **Purpose**: Unified view of orders + status
   - **Join Type**: LEFT JOIN (keep all orders, even without status yet)
   - **Join Key**: `o.order_id = s.order_identifier`
   - **Watermarking**:
     - Orders: 10 minutes (`withWatermark("order_date", "10 minutes")`)
     - Status: 10 minutes (`withWatermark("dt_current_timestamp", "10 minutes")`)
     - **Meaning**: Wait up to 10 min for late events, then drop
   - **Time Constraint**: `s.dt_current_timestamp >= o.order_date - interval 2 hours`
     - **Meaning**: Only join status within 2 hours of order
     - **Why**: Prevents unbounded state growth
   - **Data Quality Expectations** (3 rules):
     ```python
     @dlt.expect_or_drop("valid_order_id", "order_id IS NOT NULL")
     @dlt.expect_or_drop("valid_order_date", "order_date IS NOT NULL")
     @dlt.expect_or_drop("valid_total_amount", "total_amount > 0")
     ```
   - **Fields**: order_id, order_date, restaurant_key, driver_key, user_key, total_amount, status_id, status_name, status_time
   - **Type**: STREAMING TABLE
   - **Language**: Python (PySpark)

2. **silver_delayed_orders** (Filtered critical events)
   - **Purpose**: Identify orders taking too long
   - **Filter Logic**:
     ```python
     (status_name == 'preparing' AND 
      unix_timestamp(status_time) - unix_timestamp(order_date) > 1800)
     ```
     - **Meaning**: Orders in "preparing" status for > 30 minutes
   - **Use Case**: Alert operations team about delayed orders
   - **Fields**: Same as silver_order_status (filtered subset)
   - **Type**: STREAMING TABLE
   - **Language**: Python (PySpark)

**Key Concepts Demonstrated**:
- âœ… Stream-to-stream JOIN (LEFT JOIN)
- âœ… Watermarking (handle late data)
- âœ… Time-bounded joins (prevent state explosion)
- âœ… Data Quality expectations (expect_or_drop)
- âœ… Stream filtering (critical events)
- âœ… Timestamp arithmetic (detect delays)

---

### **PHASE 3: Sink Layer - External Integration**

**Duration**: 10 minutes

**What Happens**:
- **Publish** critical events to **external Kafka topic**
- Use **Databricks Sink** (dp.create_sink)
- Format messages as **key-value pairs** (Kafka standard)
- Demonstrate **exactly-once** delivery guarantee

**Why Sinks?**
- **External systems** need to be notified (alerting, monitoring)
- **Kafka** is the standard for event streaming
- **Decoupling**: Analytics in Databricks, alerting in external system
- **Real-time**: Events published as they happen

**Objects Created**:

1. **delivery_alerts_sink** (Kafka endpoint)
   - **Purpose**: Define external Kafka destination
   - **Command**:
     ```python
     dp.create_sink(
         name="delivery_alerts_sink",
         endpoint="<kafka_bootstrap_servers>",
         topic="delivery-alerts",
         format="kafka"
     )
     ```
   - **Configuration**: Bootstrap servers, topic name, format
   - **Type**: SINK (not a table)

2. **sink_kafka_alerts** (Staging table for formatting)
   - **Purpose**: Format delayed orders as Kafka messages
   - **Structure**:
     ```python
     key: order_id (STRING)
     value: JSON({
         "order_id": order_id,
         "restaurant_key": restaurant_key,
         "driver_key": driver_key,
         "delay_minutes": delay_minutes,
         "alert_type": "DELAYED_ORDER",
         "timestamp": current_timestamp()
     })
     ```
   - **Type**: STREAMING TABLE
   - **Language**: Python (PySpark)

3. **publish_to_kafka** (Append flow to sink)
   - **Purpose**: Connect staging table to sink
   - **Command**:
     ```python
     @dp.append_flow(
         target="delivery_alerts_sink",
         source="sink_kafka_alerts"
     )
     ```
   - **Behavior**: Automatically publishes new records to Kafka
   - **Guarantee**: Exactly-once delivery

**Key Concepts Demonstrated**:
- âœ… Sinks (external integration)
- âœ… dp.create_sink (define Kafka endpoint)
- âœ… Key-value message format
- âœ… dp.append_flow (publish to sink)
- âœ… Exactly-once delivery
- âœ… JSON serialization

---

### **PHASE 4: Gold Layer - Real-Time Analytics**

**Duration**: 15 minutes

**What Happens**:
- Create **real-time KPI tables** from streaming data
- Use **windowed aggregations** (10-minute tumbling windows)
- Apply **streaming-compatible functions** (approx_count_distinct)
- Generate **multiple perspectives** (restaurant, driver, system)

**The Challenge**:
Streaming aggregations have **limitations**:
- Can't use **exact COUNT(DISTINCT)** (unbounded memory)
- Can't use **window functions** (OVER clause)
- Must use **tumbling/sliding windows** for time-based aggregations

**Tables Created**:

1. **gold_restaurant_performance** (Per-restaurant metrics)
   - **Purpose**: Track each restaurant's performance in real-time
   - **Aggregation Window**: 10-minute tumbling windows
   - **Metrics**:
     ```sql
     - total_orders: COUNT(*)
     - unique_drivers: approx_count_distinct(driver_key)
     - total_revenue: SUM(total_amount)
     - avg_order_value: AVG(total_amount)
     - delayed_orders: SUM(CASE WHEN delayed THEN 1 ELSE 0 END)
     - delay_rate: delayed_orders / total_orders
     ```
   - **Dimensions**: restaurant_key, window_start, window_end
   - **Type**: STREAMING TABLE
   - **Language**: SQL

2. **gold_driver_performance** (Per-driver metrics)
   - **Purpose**: Track each driver's performance in real-time
   - **Aggregation Window**: 10-minute tumbling windows
   - **Metrics**:
     ```sql
     - total_deliveries: COUNT(*)
     - unique_restaurants: approx_count_distinct(restaurant_key)
     - total_earnings: SUM(total_amount) * 0.15 (15% commission)
     - avg_delivery_value: AVG(total_amount)
     - completed_deliveries: COUNT(CASE WHEN status = 'delivered')
     - completion_rate: completed_deliveries / total_deliveries
     ```
   - **Dimensions**: driver_key, window_start, window_end
   - **Type**: STREAMING TABLE
   - **Language**: SQL

3. **gold_delivery_time_distribution** (Speed bucketing)
   - **Purpose**: Categorize deliveries by speed
   - **Buckets**:
     ```sql
     - fast: < 30 minutes
     - normal: 30-60 minutes
     - slow: 60-90 minutes
     - very_slow: > 90 minutes
     ```
   - **Aggregation Window**: 10-minute tumbling windows
   - **Metrics**:
     ```sql
     - order_count per bucket
     - percentage per bucket
     - avg_delivery_time per bucket
     ```
   - **Type**: STREAMING TABLE
   - **Language**: SQL

4. **gold_system_health** (Platform-wide KPIs)
   - **Purpose**: Overall system health monitoring
   - **Aggregation Window**: 10-minute tumbling windows
   - **Metrics**:
     ```sql
     - total_orders: COUNT(*)
     - total_revenue: SUM(total_amount)
     - unique_users: approx_count_distinct(user_key)
     - unique_restaurants: approx_count_distinct(restaurant_key)
     - unique_drivers: approx_count_distinct(driver_key)
     - avg_order_value: AVG(total_amount)
     - orders_per_minute: total_orders / 10
     - revenue_per_minute: total_revenue / 10
     ```
   - **Dimensions**: window_start, window_end
   - **Type**: STREAMING TABLE
   - **Language**: SQL

**Key Concepts Demonstrated**:
- âœ… Windowed aggregations (tumbling windows)
- âœ… approx_count_distinct (streaming-compatible)
- âœ… Multiple aggregation perspectives
- âœ… Real-time KPIs
- âœ… CASE expressions for conditional aggregations
- âœ… Time bucketing (CASE for speed categories)

---

## ğŸ¨ Excalidraw Elements

### **1. Title Box**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USE CASE 1: REAL-TIME DELIVERY         â”‚
â”‚  MONITORING WITH STREAMING              â”‚
â”‚                                         â”‚
â”‚  Problem: Monitor 10,000+ deliveries/secâ”‚
â”‚           Detect delays in < 3 seconds  â”‚
â”‚  Solution: Streaming pipeline + Sinks   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **2. Data Sources (Top)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ“¥ DATA SOURCES (Kafka)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  ğŸŒŠ kafka/orders/                        â”‚
â”‚  â”œâ”€ New orders from customers            â”‚
â”‚  â”œâ”€ Fields: order_id, restaurant_key,    â”‚
â”‚  â”‚   driver_key, total_amount            â”‚
â”‚  â”œâ”€ Volume: ~5,000 events/sec            â”‚
â”‚  â””â”€ Latency: < 100ms                     â”‚
â”‚                                          â”‚
â”‚  ğŸŒŠ kafka/status/                        â”‚
â”‚  â”œâ”€ Delivery status updates              â”‚
â”‚  â”œâ”€ Fields: order_identifier, status_id, â”‚
â”‚  â”‚   status_name                         â”‚
â”‚  â”œâ”€ Volume: ~5,000 events/sec            â”‚
â”‚  â””â”€ Latency: < 100ms                     â”‚
â”‚                                          â”‚
â”‚  Join Key: order_id = order_identifier   â”‚
â”‚  Processing: Real-time streaming         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Excalidraw Instructions**:
- Two boxes side by side (orders left, status right)
- Use streaming wave icon (ğŸŒŠ)
- Color: Blue (#4A90E2) - represents streaming
- Arrow pointing down to Bronze
- Annotate with "10,000+ events/sec"

---

### **3. Bronze Layer**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸŸ¤ BRONZE LAYER (Streaming Ingestion)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  [STREAMING TABLE - Python]              â”‚
â”‚  bronze_orders                           â”‚
â”‚  â”œâ”€ Method: Auto Loader (cloudFiles)     â”‚
â”‚  â”œâ”€ Features: Schema hints, metadata     â”‚
â”‚  â”œâ”€ CDF: Enabled                         â”‚
â”‚  â””â”€ Latency: < 1 second                  â”‚
â”‚                                          â”‚
â”‚  [STREAMING TABLE - SQL]                 â”‚
â”‚  bronze_status                           â”‚
â”‚  â”œâ”€ Method: read_files()                 â”‚
â”‚  â”œâ”€ Features: Nested extraction          â”‚
â”‚  â”œâ”€ CDF: Enabled                         â”‚
â”‚  â””â”€ Latency: < 1 second                  â”‚
â”‚                                          â”‚
â”‚  Type: STREAMING TABLE (Continuous)      â”‚
â”‚  Processing: Event-by-event              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Excalidraw Instructions**:
- Rectangle box
- Color: Brown (#8B5A2B)
- Two sub-boxes inside (one for each table)
- Label: "Python" and "SQL" to show different approaches
- Arrow pointing down to Silver
- Annotate: "Two approaches, same result"

---

### **4. Silver Layer (Stream Processing)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¥ˆ SILVER LAYER (Stream Joins & Filtering)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [STREAMING TABLE - Stream-to-stream JOIN]                  â”‚
â”‚  silver_order_status                                         â”‚
â”‚  â”œâ”€ Join: bronze_orders LEFT JOIN bronze_status             â”‚
â”‚  â”œâ”€ Watermark: 10 minutes on both sides                     â”‚
â”‚  â”œâ”€ Time Constraint: status within 2 hours of order         â”‚
â”‚  â”œâ”€ Data Quality: 3 expectations (expect_or_drop)           â”‚
â”‚  â”‚   â€¢ valid_order_id: order_id IS NOT NULL                 â”‚
â”‚  â”‚   â€¢ valid_order_date: order_date IS NOT NULL             â”‚
â”‚  â”‚   â€¢ valid_total_amount: total_amount > 0                 â”‚
â”‚  â””â”€ Latency: < 2 seconds                                    â”‚
â”‚                                                              â”‚
â”‚  [STREAMING TABLE - Filtered Events]                        â”‚
â”‚  silver_delayed_orders                                       â”‚
â”‚  â”œâ”€ Filter: status = 'preparing' AND delay > 30 min         â”‚
â”‚  â”œâ”€ Purpose: Critical events for alerting                   â”‚
â”‚  â””â”€ Latency: < 2 seconds                                    â”‚
â”‚                                                              â”‚
â”‚  Key Concepts:                                               â”‚
â”‚  â€¢ Watermarking handles late data                           â”‚
â”‚  â€¢ Time-bounded join prevents state explosion               â”‚
â”‚  â€¢ Expectations drop invalid records automatically          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Excalidraw Instructions**:
- Large rectangle box
- Color: Gray/Silver (#C0C0C0)
- Two sub-boxes (stacked vertically)
- Top box: Emphasize "LEFT JOIN" and "Watermark: 10 min"
- Bottom box: Emphasize "Filter: delay > 30 min"
- Two arrows pointing down: one to Sink, one to Gold
- Annotate: "Stream-to-stream JOIN with watermarking"

---

### **5. Sink Layer (External Integration)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ“¤ SINK LAYER (External Kafka Publishing)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Step 1: Define Sink                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ delivery_alerts_sink                           â”‚         â”‚
â”‚  â”‚ â”œâ”€ Type: Kafka                                 â”‚         â”‚
â”‚  â”‚ â”œâ”€ Topic: delivery-alerts                      â”‚         â”‚
â”‚  â”‚ â””â”€ Guarantee: Exactly-once                     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                              â”‚
â”‚  Step 2: Format Messages                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ sink_kafka_alerts (Staging)                    â”‚         â”‚
â”‚  â”‚ â”œâ”€ key: order_id                               â”‚         â”‚
â”‚  â”‚ â”œâ”€ value: JSON({order_id, restaurant_key,     â”‚         â”‚
â”‚  â”‚ â”‚         driver_key, delay_minutes, ...})     â”‚         â”‚
â”‚  â”‚ â””â”€ Source: silver_delayed_orders               â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                              â”‚
â”‚  Step 3: Publish                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ @dp.append_flow(                               â”‚         â”‚
â”‚  â”‚   target="delivery_alerts_sink",               â”‚         â”‚
â”‚  â”‚   source="sink_kafka_alerts"                   â”‚         â”‚
â”‚  â”‚ )                                              â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                              â”‚
â”‚  Latency: < 3 seconds (end-to-end)                          â”‚
â”‚  Consumers: Alerting systems, Monitoring tools               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Excalidraw Instructions**:
- Rectangle box (separate from main flow, to the right)
- Color: Orange (#F5A623) - represents external integration
- Three steps (stacked vertically)
- Arrow from silver_delayed_orders to sink
- Arrow from sink to external Kafka icon
- Annotate: "Exactly-once delivery to external Kafka"

---

### **6. Gold Layer (Real-Time Analytics)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¥‡ GOLD LAYER (Real-Time KPIs)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [STREAMING TABLE] gold_restaurant_performance               â”‚
â”‚  â”œâ”€ Window: 10-minute tumbling                              â”‚
â”‚  â”œâ”€ Metrics: total_orders, unique_drivers, revenue,         â”‚
â”‚  â”‚   avg_order_value, delay_rate                            â”‚
â”‚  â”œâ”€ Group By: restaurant_key, window                        â”‚
â”‚  â””â”€ Use: Restaurant dashboard                               â”‚
â”‚                                                              â”‚
â”‚  [STREAMING TABLE] gold_driver_performance                   â”‚
â”‚  â”œâ”€ Window: 10-minute tumbling                              â”‚
â”‚  â”œâ”€ Metrics: total_deliveries, unique_restaurants,          â”‚
â”‚  â”‚   earnings, completion_rate                              â”‚
â”‚  â”œâ”€ Group By: driver_key, window                            â”‚
â”‚  â””â”€ Use: Driver dashboard                                   â”‚
â”‚                                                              â”‚
â”‚  [STREAMING TABLE] gold_delivery_time_distribution           â”‚
â”‚  â”œâ”€ Window: 10-minute tumbling                              â”‚
â”‚  â”œâ”€ Buckets: fast (<30m), normal (30-60m), slow (60-90m),  â”‚
â”‚  â”‚   very_slow (>90m)                                       â”‚
â”‚  â”œâ”€ Metrics: count, percentage per bucket                   â”‚
â”‚  â””â”€ Use: Operations monitoring                              â”‚
â”‚                                                              â”‚
â”‚  [STREAMING TABLE] gold_system_health                        â”‚
â”‚  â”œâ”€ Window: 10-minute tumbling                              â”‚
â”‚  â”œâ”€ Metrics: total_orders, revenue, unique_users,           â”‚
â”‚  â”‚   restaurants, drivers, orders_per_minute                â”‚
â”‚  â”œâ”€ Group By: window only (platform-wide)                   â”‚
â”‚  â””â”€ Use: Executive dashboard                                â”‚
â”‚                                                              â”‚
â”‚  Key: approx_count_distinct (streaming-compatible)           â”‚
â”‚  Update Frequency: Every 10 minutes                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Excalidraw Instructions**:
- Rectangle box
- Color: Gold/Yellow (#FFD700)
- Four sub-boxes (stacked vertically, or 2x2 grid)
- Each labeled "STREAMING TABLE"
- Emphasize "10-minute windows" and "approx_count_distinct"
- Arrows pointing down to Consumers
- Annotate: "Real-time KPIs updated every 10 minutes"

---

### **7. Consumers (Bottom)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ“Š CONSUMERS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Operations Team:                        â”‚
â”‚  â”œâ”€ Real-time delivery monitoring        â”‚
â”‚  â”œâ”€ Delayed order alerts                 â”‚
â”‚  â””â”€ System health dashboard              â”‚
â”‚                                          â”‚
â”‚  Restaurant Partners:                    â”‚
â”‚  â”œâ”€ Performance metrics                  â”‚
â”‚  â””â”€ Order volume tracking                â”‚
â”‚                                          â”‚
â”‚  Drivers:                                â”‚
â”‚  â”œâ”€ Earnings dashboard                   â”‚
â”‚  â””â”€ Completion rate tracking             â”‚
â”‚                                          â”‚
â”‚  External Systems:                       â”‚
â”‚  â”œâ”€ Kafka consumers (alerting)           â”‚
â”‚  â”œâ”€ Monitoring tools (PagerDuty)         â”‚
â”‚  â””â”€ ML models (demand forecasting)       â”‚
â”‚                                          â”‚
â”‚  Update Latency: < 3 seconds             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Excalidraw Instructions**:
- Rectangle box at bottom
- Color: Blue (#4A90E2)
- Four sections (Operations, Restaurants, Drivers, External)
- Use icons: ğŸ“Š ğŸ“ˆ ğŸš¨ ğŸ‘¥
- Arrow from Gold layer
- Arrow from Sink layer to "External Systems"

---

### **8. Key Concepts Box (Side annotation)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KEY CONCEPTS DEMONSTRATED              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  âœ… STREAMING TABLES                    â”‚
â”‚     Continuous processing               â”‚
â”‚                                         â”‚
â”‚  âœ… AUTO LOADER (cloudFiles)            â”‚
â”‚     Python approach                     â”‚
â”‚                                         â”‚
â”‚  âœ… read_files()                        â”‚
â”‚     SQL approach                        â”‚
â”‚                                         â”‚
â”‚  âœ… STREAM-TO-STREAM JOIN               â”‚
â”‚     LEFT JOIN with watermarking         â”‚
â”‚                                         â”‚
â”‚  âœ… WATERMARKING                        â”‚
â”‚     Handle late-arriving data           â”‚
â”‚                                         â”‚
â”‚  âœ… TIME-BOUNDED JOIN                   â”‚
â”‚     Prevent state explosion             â”‚
â”‚                                         â”‚
â”‚  âœ… DATA QUALITY (Expectations)         â”‚
â”‚     expect_or_drop decorators           â”‚
â”‚                                         â”‚
â”‚  âœ… SINKS                               â”‚
â”‚     Publish to external Kafka           â”‚
â”‚                                         â”‚
â”‚  âœ… WINDOWED AGGREGATIONS               â”‚
â”‚     10-minute tumbling windows          â”‚
â”‚                                         â”‚
â”‚  âœ… approx_count_distinct               â”‚
â”‚     Streaming-compatible aggregation    â”‚
â”‚                                         â”‚
â”‚  âœ… MEDALLION ARCHITECTURE              â”‚
â”‚     Bronze â†’ Silver â†’ Gold + Sink       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Excalidraw Instructions**:
- Place on right side of diagram
- Color: Light blue background
- Checkmarks (âœ…) for each concept
- Connect to relevant layers with dotted lines

---

### **9. Data Flow Arrows**

**Arrows to draw**:

1. **Sources â†’ Bronze**: Two parallel arrows
   - Label: "Streaming ingestion (< 1s)"
   - Color: Blue (streaming)

2. **Bronze â†’ Silver**: Two arrows converging
   - Label: "Stream-to-stream JOIN (LEFT JOIN)"
   - Annotate: "Watermark: 10 min, Time constraint: 2 hours"

3. **Silver â†’ Sink**: One arrow to the right
   - Label: "Critical events only (delayed orders)"
   - Color: Orange

4. **Silver â†’ Gold**: One arrow down
   - Label: "Windowed aggregations (10-min windows)"
   - Color: Yellow

5. **Sink â†’ External Kafka**: Arrow to external system
   - Label: "Exactly-once delivery"
   - Dashed line (external boundary)

6. **Gold â†’ Consumers**: Multiple arrows to different consumer boxes
   - Label: "Real-time dashboards (< 3s latency)"

---

### **10. Annotations (Callout boxes)**

**Annotation 1** (near Bronze):
```
ğŸ’¡ Python vs SQL
Same result, different syntax!
- Python: Auto Loader (cloudFiles)
- SQL: read_files()
Choose what fits your team!
```

**Annotation 2** (near Silver JOIN):
```
ğŸ’¡ Stream-to-stream JOIN
Challenge: Both sides are unbounded
Solution: Watermarking + Time constraint
- Watermark: Wait 10 min for late data
- Time constraint: Only join within 2 hours
Result: Bounded state, no OOM!
```

**Annotation 3** (near Expectations):
```
ğŸ’¡ Data Quality
3 expectations drop invalid records:
- valid_order_id (NOT NULL)
- valid_order_date (NOT NULL)
- valid_total_amount (> 0)
No manual filtering needed!
```

**Annotation 4** (near Sink):
```
ğŸ’¡ Why Sinks?
External systems need alerts!
- Kafka: Standard event streaming
- Exactly-once: No duplicates
- Decoupled: Analytics â‰  Alerting
```

**Annotation 5** (near Gold):
```
ğŸ’¡ Streaming Aggregations
Limitations:
- No exact COUNT(DISTINCT) â†’ use approx
- No window functions (OVER clause)
- Must use tumbling/sliding windows
Result: 98% accurate, fixed memory!
```

**Annotation 6** (near end-to-end):
```
ğŸ’¡ End-to-End Latency
Event â†’ Bronze: < 1s
Bronze â†’ Silver: < 1s
Silver â†’ Gold/Sink: < 1s
Total: < 3 seconds! âš¡
```

---

## ğŸ“Š Complete Excalidraw Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚  [TITLE BOX]                                                             â”‚
â”‚  USE CASE 1: REAL-TIME DELIVERY MONITORING                               â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚  Kafka       â”‚          â”‚  Kafka       â”‚                             â”‚
â”‚  â”‚  orders/     â”‚          â”‚  status/     â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚         â”‚                         â”‚                                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                      â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  ğŸŸ¤ BRONZE LAYER                            â”‚  [Annotation 1]        â”‚
â”‚  â”‚  â”œâ”€ bronze_orders (Python Auto Loader)      â”‚  Python vs SQL        â”‚
â”‚  â”‚  â””â”€ bronze_status (SQL read_files)          â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                    â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  ğŸ¥ˆ SILVER LAYER                            â”‚                        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  [Annotation 2]        â”‚
â”‚  â”‚  â”‚ silver_order_status             â”‚        â”‚  Stream JOIN          â”‚
â”‚  â”‚  â”‚ LEFT JOIN + Watermarking        â”‚        â”‚                        â”‚
â”‚  â”‚  â”‚ 3 Expectations (expect_or_drop) â”‚        â”‚  [Annotation 3]        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  Data Quality         â”‚
â”‚  â”‚               â†“                             â”‚                        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                        â”‚
â”‚  â”‚  â”‚ silver_delayed_orders           â”‚        â”‚                        â”‚
â”‚  â”‚  â”‚ Filter: delay > 30 min          â”‚        â”‚                        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚              â”‚              â”‚                                           â”‚
â”‚              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚              â”‚                             â†“                            â”‚
â”‚              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚              â”‚              â”‚  ğŸ“¤ SINK LAYER           â”‚ [Annotation 4] â”‚
â”‚              â”‚              â”‚  â”œâ”€ delivery_alerts_sink â”‚ Why Sinks?    â”‚
â”‚              â”‚              â”‚  â”œâ”€ sink_kafka_alerts    â”‚                â”‚
â”‚              â”‚              â”‚  â””â”€ @dp.append_flow      â”‚                â”‚
â”‚              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚              â”‚                         â”‚                                â”‚
â”‚              â”‚                         â†“                                â”‚
â”‚              â”‚              [External Kafka] ğŸŒ                         â”‚
â”‚              â”‚                                                          â”‚
â”‚              â†“                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  ğŸ¥‡ GOLD LAYER                              â”‚  [Annotation 5]        â”‚
â”‚  â”‚  â”œâ”€ gold_restaurant_performance             â”‚  Streaming Aggs       â”‚
â”‚  â”‚  â”œâ”€ gold_driver_performance                 â”‚                        â”‚
â”‚  â”‚  â”œâ”€ gold_delivery_time_distribution         â”‚  [Annotation 6]        â”‚
â”‚  â”‚  â””â”€ gold_system_health                      â”‚  Latency < 3s         â”‚
â”‚  â”‚                                             â”‚                        â”‚
â”‚  â”‚  Window: 10-minute tumbling                 â”‚                        â”‚
â”‚  â”‚  Function: approx_count_distinct            â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                    â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  ğŸ“Š CONSUMERS                               â”‚                        â”‚
â”‚  â”‚  â”œâ”€ Operations (Monitoring)                 â”‚                        â”‚
â”‚  â”‚  â”œâ”€ Restaurants (Performance)               â”‚                        â”‚
â”‚  â”‚  â”œâ”€ Drivers (Earnings)                      â”‚                        â”‚
â”‚  â”‚  â””â”€ External Systems (Alerts)               â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                          â”‚
â”‚  [KEY CONCEPTS BOX - Right side]                                        â”‚
â”‚  âœ… Streaming Tables                                                     â”‚
â”‚  âœ… Auto Loader / read_files                                             â”‚
â”‚  âœ… Stream-to-stream JOIN                                                â”‚
â”‚  âœ… Watermarking                                                         â”‚
â”‚  âœ… Sinks (External Kafka)                                               â”‚
â”‚  âœ… Windowed Aggregations                                                â”‚
â”‚  âœ… approx_count_distinct                                                â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Phase Summary

### **Phase 1: Bronze (10 min)**
- **What**: Ingest streaming data from Kafka
- **How**: Streaming Tables (Python Auto Loader + SQL read_files)
- **Why**: Real-time delivery events need continuous processing
- **Output**: 2 Bronze tables (orders + status)

### **Phase 2: Silver (15 min)**
- **What**: Join streams + Filter critical events
- **How**: Stream-to-stream JOIN with watermarking + Expectations
- **Why**: Unified view of deliveries + Detect delays
- **Output**: 2 Silver tables (unified + delayed)

### **Phase 3: Sink (10 min)**
- **What**: Publish critical events to external Kafka
- **How**: dp.create_sink + dp.append_flow
- **Why**: External systems need real-time alerts
- **Output**: 1 Kafka sink (delivery-alerts topic)

### **Phase 4: Gold (15 min)**
- **What**: Real-time KPIs and analytics
- **How**: Windowed aggregations with approx_count_distinct
- **Why**: Operations, restaurants, drivers need live metrics
- **Output**: 4 Gold tables (restaurant, driver, distribution, system)

---

## ğŸ’¡ Real-World Production Scenario

**Company**: UberEats (Food Delivery Platform)

**Problem**:
- **Operations** needs to monitor 10,000+ deliveries in real-time
- **Delayed orders** must be detected in < 3 seconds
- **External systems** (PagerDuty, Slack) need instant alerts
- **Restaurants/Drivers** need live performance dashboards

**Solution**:
Build a **Real-Time Streaming Pipeline** that:
1. âœ… Ingests Kafka streams continuously (orders + status)
2. âœ… Joins streams with watermarking (handle late data)
3. âœ… Filters critical events (delayed orders)
4. âœ… Publishes to external Kafka (Sinks)
5. âœ… Generates real-time KPIs (windowed aggregations)

**Business Impact**:
- ğŸ“ˆ **Operations**: 80% faster incident detection (< 3s vs 15s)
- ğŸ“ˆ **Customer Satisfaction**: 25% fewer complaints (proactive alerts)
- ğŸ“ˆ **Restaurant Partners**: 40% better planning (real-time metrics)
- ğŸ“ˆ **Drivers**: 30% higher earnings (optimized routing based on data)

---

## ğŸš€ Technical Highlights

### **Why This Use Case is Production-Grade**:

1. **Real Problem**: Monitor thousands of real-time deliveries (every delivery platform has this)
2. **Real Solution**: Streaming pipeline with Sinks (industry standard)
3. **Real Complexity**: Stream-to-stream joins, watermarking, late data handling
4. **Real Integration**: External Kafka for alerting (decoupled architecture)

### **What Students Learn**:

- âœ… When to use **Streaming Tables** vs Materialized Views
- âœ… How to **join** two streaming sources (watermarking + time constraints)
- âœ… How to handle **late-arriving data** (watermarking)
- âœ… How to apply **Data Quality** (expectations)
- âœ… How to **publish to external systems** (Sinks)
- âœ… How to create **real-time KPIs** (windowed aggregations)
- âœ… Why use **approx_count_distinct** (streaming limitations)
- âœ… How to design **low-latency pipelines** (< 3s end-to-end)

---

## ğŸ“‹ File Mapping (Your Actual Implementation)

| Layer | File | Language | Table/Object |
|:------|:-----|:---------|:-------------|
| Bronze | 01-bronze-orders.py | Python | bronze_orders |
| Bronze | 01-bronze-status.sql | SQL | bronze_status |
| Silver | 02-silver-order-status.py | Python | silver_order_status |
| Silver | 02-silver-delayed-orders.py | Python | silver_delayed_orders |
| Sink | 04-sink-layer.py | Python | delivery_alerts_sink + sink_kafka_alerts |
| Gold | 03-gold-restaurant-performance.sql | SQL | gold_restaurant_performance |
| Gold | 03-gold-driver-performance.sql | SQL | gold_driver_performance |
| Gold | 03-gold-delivery-time-distribution.sql | SQL | gold_delivery_time_distribution |
| Gold | 03-gold-system-health.sql | SQL | gold_system_health |

**Total**: 9 files â†’ 8 streaming tables + 1 Kafka sink

---

**This use case perfectly demonstrates Lakeflow's power for real-time streaming scenarios!** ğŸ“ğŸš€

